{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TTbarResCoffea` Notebook to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "This module must be run twice: \n",
    "   1. Make the mistag rate in the \"anti-tag and probe\" selection \n",
    "and the expectation in the signal region from MC,\n",
    "   1. Applies that mistag rate and the mod-mass procedure to the single-tag selection. \n",
    "\n",
    "These are all done in bins of\n",
    "b-tag categories (0, 1, $\\ge 2$) and rapidity difference ($|y_1 - y_2| \\le 1.0$, $|y_1 - y_2| > 1.0$).\n",
    "The signal region is two top-tagged jets. \n",
    "The background estimate is the single-tag selection weighted by the mistag rate from the\n",
    "\"anti-tag and probe\" region, with the mass of the weighted jet set to a random\n",
    "value from QCD MC in the 1-ttag region. \n",
    "\n",
    "\n",
    "The preselection is:\n",
    "- AK4-based $H_{T} > 1100$ GeV (to be on the trigger plateau). \n",
    "- $\\ge 2$ AK8 jets with AK8 $p_{T} > 400$ GeV and $|\\eta| < 2.5$, loose jet ID applied from matched AK4 jets\n",
    "\n",
    "The 1-tag selection adds:\n",
    "- $\\ge 1$ AK8 jet with top tagging applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The anti-tag selection is disjoint from the 1-tag selection:\n",
    "- $\\ge 1$ AK8 jet with top tagging VETO applied to randomly-assigned tag jet. \n",
    "\n",
    "\n",
    "The 2-tag selection is:\n",
    "- $\\ge 2$ AK8 jets with top tagging applied to both leading jets. \n",
    "\n",
    "\n",
    "The ttbar candidate mass assumes the two leading top-tagged jets are the top quarks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from coffea import util\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrootdstr1 = 'root://cmseos.fnal.gov//'\n",
    "xrootdstr2 = 'root://cmsxrootd.fnal.gov//'\n",
    "xrootdstr3 = 'root://cmsxrootd-site.fnal.gov/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcdfilename = 'QCD.txt'\n",
    "with open(qcdfilename) as f:\n",
    "    qcdfiles = [xrootdstr2 + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttbarfilename = 'TTJets_TuneCP5_13TeV-amcatnloFXFX-pythia8.txt'\n",
    "with open(ttbarfilename) as f:\n",
    "    ttbarfiles = [xrootdstr2 + s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetdatafilename = 'JetHT_Data.txt'\n",
    "with open(jetdatafilename) as f:\n",
    "    jetdatafiles = [xrootdstr2 + s.strip() for s in f.readlines()[::3]] # Every third datafile\n",
    "with open(jetdatafilename) as g:\n",
    "    jetdatafiles2016 = [xrootdstr2 + s.strip() for s in g.readlines() if \"/store/data/Run2016\" in s]\n",
    "with open(jetdatafilename) as h:\n",
    "    jetdatafiles2017 = [xrootdstr2 + s.strip() for s in h.readlines() if \"/store/data/Run2017\" in s]\n",
    "with open(jetdatafilename) as i:\n",
    "    jetdatafiles2018 = [xrootdstr2 + s.strip() for s in i.readlines() if \"/store/data/Run2018\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(jetdatafiles[2]) # Test to see if correct files are collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from columnservice.client import ColumnClient\n",
    "cc = ColumnClient(\"coffea-dask.fnal.gov\")\n",
    "client = cc.get_dask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bins = [400, 500, 600, 800, 1000, 1500, 2000, 3000, 7000]\n",
    "ttagcats = [\"At\",\"at\", \"0t\", \"1t\", \"2t\"] #anti-tag+probe, anti-tag, 0, 1, >=2 ttags\n",
    "btagcats = [\"0b\", \"1b\", \"2b\"]   # 0, 1, >=2 btags\n",
    "ycats = ['cen', 'fwd']          # Central and forward\n",
    "# Combine categories like \"0bcen\", \"0bfwd\", etc:\n",
    "anacats = [ t+b+y for t,b,y in itertools.product( ttagcats, btagcats, ycats) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"@TTbarResAnaHadronic Package to perform the data-driven mistag-rate-based ttbar hadronic analysis. \n",
    "\"\"\"\n",
    "class TTbarResProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, prng, htCut=950., minMSD=105., maxMSD=210., tau32Cut=0.65, ak8PtMin=400., bdisc=0.8484,\n",
    "                writePredDist=True,isData=True,year=2019, UseLookUpTables=False,\n",
    "                lu = None):\n",
    "        \n",
    "        self.prng = prng\n",
    "        self.htCut = htCut\n",
    "        self.minMSD = minMSD\n",
    "        self.maxMSD = maxMSD\n",
    "        self.tau32Cut = tau32Cut\n",
    "        self.ak8PtMin = ak8PtMin\n",
    "        self.bdisc = bdisc\n",
    "        self.writePredDist = writePredDist\n",
    "        self.writeHistFile = True\n",
    "        self.isData = isData\n",
    "        self.year=year\n",
    "        self.UseLookUpTables = UseLookUpTables\n",
    "        self.lu = lu # Look Up Tables\n",
    "        \n",
    "        self.anacats = anacats\n",
    "        print(self.anacats)\n",
    "        \n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        cats_axis = hist.Cat(\"anacat\", \"Analysis Category\")\n",
    "\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'cutflow': processor.defaultdict_accumulator(int),\n",
    "            \n",
    "        })\n",
    "\n",
    "            \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        \n",
    "        output = self.accumulator.identity()\n",
    "        #dataset = events.metadata['dataset']\n",
    "        \n",
    "        # ---- Define dataset ---- #\n",
    "        dataset = df['dataset'] #coffea.processor.LazyDataFrame\n",
    "        Dataset_info = df.available #list of available columns in LazyDataFrame object (Similar to 'Events->Show()' command in ROOT)\n",
    "        \n",
    "        # ---- Define AK8 Jets as FatJets ---- #\n",
    "        FatJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'],\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            area=df['FatJet_area'],\n",
    "            msoftdrop=df['FatJet_msoftdrop'],\n",
    "            jetId=df['FatJet_jetId'],\n",
    "            )\n",
    "        \n",
    "        # ---- Define AK4 jets as Jets ---- #\n",
    "        Jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['Jet_pt'],\n",
    "            eta=df['Jet_eta'],\n",
    "            phi=df['Jet_phi'],\n",
    "            mass=df['Jet_mass']\n",
    "            )\n",
    "        \n",
    "        \n",
    "        # ---- Get event weights from dataset ---- #\n",
    "        if 'JetHT' in dataset: # If data is used...\n",
    "            evtweights = np.ones(FatJets.size) # set all \"data weights\" to one\n",
    "        else: # if Monte Carlo dataset is used...\n",
    "            evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        \n",
    "        # ---- Show all events ---- #\n",
    "        output['cutflow']['all events'] += FatJets.size\n",
    "    \n",
    "        # ---- Jets that satisfy Jet ID ---- #\n",
    "        jet_id = (FatJets.jetId > 0)\n",
    "        FatJets = FatJets[jet_id]\n",
    "        output['cutflow']['jet id'] += jet_id.any().sum()\n",
    "        \n",
    "        # ---- Apply Eta cut ---- #\n",
    "        jetkincut_index = (FatJets.pt > self.ak8PtMin) & (np.abs(FatJets.eta) < 2.5) # eta cut here\n",
    "        FatJets = FatJets[ jetkincut_index ]\n",
    "        output['cutflow']['jet kin'] += jetkincut_index.any().sum()\n",
    "        \n",
    "        # ---- Ensure that FatJets are AK8 Jets ---- #\n",
    "        #ak8Jets = FatJets.area > np.pi*0.8**2\n",
    "        #FatJets = FatJets[ak8Jets]\n",
    "        \n",
    "        # ---- Find at least two AK8 Jets ---- #\n",
    "        twoFatJetsKin = (FatJets.counts >= 2)\n",
    "        FatJets = FatJets[twoFatJetsKin]\n",
    "        evtweights = evtweights[twoFatJetsKin]\n",
    "        Jets = Jets[twoFatJetsKin]\n",
    "        output['cutflow']['two FatJets and jet kin'] += twoFatJetsKin.sum()\n",
    "        \n",
    "        # ---- Apply HT Cut ---- #\n",
    "        #ak4Jets = Jets.area > np.pi*0.4**2\n",
    "        #Jets = Jets[ak4Jets]\n",
    "        hT = Jets.pt.sum()\n",
    "        passhT = (hT > self.htCut)\n",
    "        evtweights = evtweights[passhT]\n",
    "        FatJets = FatJets[passhT]\n",
    "        \n",
    "        # ---- Randomly Select AK8 Jet as TTbar Candidate --- #\n",
    "        highPhi = FatJets.phi[:,0] > FatJets.phi[:,1]\n",
    "        highRandIndex = np.where(highPhi, 0, 1)\n",
    "        #index = JaggedArray.fromcounts(np.ones(len(FatJets), dtype='i'), prng.randint(2, size=len(FatJets)))\n",
    "        index = JaggedArray.fromcounts(np.ones(len(FatJets), dtype='i'), highRandIndex )\n",
    "        jet0 = FatJets[index]\n",
    "        jet1 = FatJets[1 - index]\n",
    "        \n",
    "        ttbarcands = jet0.cross(jet1) #FatJets[:,0:2].distincts()\n",
    "        \n",
    "        # ---- Look for at least 1 TTbar candidate pair and re-broadcast releveant arrays  ---- #\n",
    "        oneTTbar = (ttbarcands.counts >= 1)\n",
    "        output['cutflow']['>= one oneTTbar'] += oneTTbar.sum()\n",
    "        ttbarcands = ttbarcands[oneTTbar]\n",
    "        evtweights = evtweights[oneTTbar]\n",
    "        FatJets = FatJets[oneTTbar]\n",
    "         \n",
    "        # ---- Apply Delta Phi Cut for Back to Back Topology ---- #\n",
    "        dPhiCut = (ttbarcands.i0.p4.delta_phi(ttbarcands.i1.p4) > 2.1).flatten()\n",
    "        output['cutflow']['dPhi > 2.1'] += dPhiCut.sum()\n",
    "        ttbarcands = ttbarcands[dPhiCut]\n",
    "        evtweights = evtweights[dPhiCut]\n",
    "        FatJets = FatJets[dPhiCut] \n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesets = {\n",
    "    #'QCD':qcdfiles,\n",
    "    #'TTbar':ttbarfiles\n",
    "    #'JetHT':jetdatafiles,\n",
    "    'JetHT2016_Data':jetdatafiles2016,\n",
    "    #'JetHT2017_Data':jetdatafiles2017,\n",
    "    #'JetHT2018_Data':jetdatafiles2018\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JetHT2016_Data\n",
      "['At0bcen', 'At0bfwd', 'At1bcen', 'At1bfwd', 'At2bcen', 'At2bfwd', 'at0bcen', 'at0bfwd', 'at1bcen', 'at1bfwd', 'at2bcen', 'at2bfwd', '0t0bcen', '0t0bfwd', '0t1bcen', '0t1bfwd', '0t2bcen', '0t2bfwd', '1t0bcen', '1t0bfwd', '1t1bcen', '1t1bfwd', '1t2bcen', '1t2bfwd', '2t0bcen', '2t0bfwd', '2t1bcen', '2t1bfwd', '2t2bcen', '2t2bfwd']\n",
      "{'cutflow': defaultdict_accumulator(<class 'int'>, {'all events': 482037634, 'jet id': 346627975, 'jet kin': 102033945, 'two FatJets and jet kin': 44604370, '>= one oneTTbar': 35666932, 'dPhi > 2.1': 18538112})}\n"
     ]
    }
   ],
   "source": [
    "tstart = time.time()\n",
    "\n",
    "outputs_unweighted = {}\n",
    "\n",
    "seed = 1234567890\n",
    "prng = RandomState(seed)\n",
    "\n",
    "for name,files in filesets.items(): \n",
    "    \n",
    "\n",
    "    print(name)\n",
    "    output = processor.run_uproot_job({name:files},\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=TTbarResProcessor(UseLookUpTables=False,\n",
    "                                                                          prng=prng),\n",
    "                                      executor=processor.dask_executor,\n",
    "                                      #executor=processor.iterative_executor,\n",
    "                                      #executor=processor.futures_executor,\n",
    "                                      executor_args={\n",
    "                                          'client': client, \n",
    "                                          'nano':False, \n",
    "                                          'flatten':True, \n",
    "                                          'skipbadfiles':False,\n",
    "                                          'workers': 4},\n",
    "                                      chunksize=100000#, maxchunks=1000\n",
    "                                     )\n",
    "\n",
    "    elapsed = time.time() - tstart\n",
    "    outputs_unweighted[name] = output\n",
    "    print(output)\n",
    "    util.save(output, 'TTbarResCoffea_' + name + '_unweighted_output.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time =  881.1625776290894  sec.\n",
      "Elapsed time =  14.686042960484823  min.\n",
      "Elapsed time =  0.24476738267474704  hrs.\n"
     ]
    }
   ],
   "source": [
    "print('Elapsed time = ', elapsed, ' sec.')\n",
    "print('Elapsed time = ', elapsed/60., ' min.')\n",
    "print('Elapsed time = ', elapsed/3600., ' hrs.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Unweighted JetHT2016_Data--------\n",
      "          all events :    482037634\n",
      "              jet id :    346627975\n",
      "             jet kin :    102033945\n",
      "two FatJets and jet kin :     44604370\n",
      "     >= one oneTTbar :     35666932\n",
      "          dPhi > 2.1 :     18538112\n"
     ]
    }
   ],
   "source": [
    "for name,output in outputs_unweighted.items(): \n",
    "    print(\"-------Unweighted \" + name + \"--------\")\n",
    "    for i,j in output['cutflow'].items():        \n",
    "        print( '%20s : %12d' % (i,j) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
